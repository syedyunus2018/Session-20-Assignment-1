{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. What are the three stages to build the hypotheses or model in machine learning?\n",
    "\n",
    "Answer: Following are the three stages to build the hypotheses or model in machine learning:\n",
    "\n",
    "a) Model building\n",
    "\n",
    "b) Model testing\n",
    "\n",
    "c) Applying the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. What is the standard approach to supervised learning?\n",
    "\n",
    "Answer: The standard approach to supervised learning is to split the set of example into the training set and the test.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. What is Training set and Test set?\n",
    "\n",
    "Answer: Training Set: In Machine Learning, a training set is a dataset used to train a model. In training the model, specific features are picked out from the training set. These features are then incorporated into the model. Thereby, if the training set is labeled correctly, the model should be able to learn something from these features.\n",
    "\n",
    "Test Set: The test set is a dataset used to measure how well the model performs at making predictions on that test set. If the prediction scores for the test set are unreasonable, weâ€™ll have to make some adjustments to our model and try again."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?\n",
    "\n",
    "Answer: General principle of an ensemble method: \n",
    "\n",
    "The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.\n",
    "\n",
    "Bagging in ensemble method: Bagging is a method in ensemble for improving unstable estimation or classification schemes. Bagging both can reduce errors by reducing the variance term.\n",
    "\n",
    "Boosting in ensemble method: Boosting method are used sequentially to reduce the bias of the combined model. Boosting can reduce errors by reducing the variance term."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. How can you avoid overfitting ?\n",
    "\n",
    "Answer: We can avoid overfitting by using the following:\n",
    "\n",
    "a) By using a lot of data: By using a lot of data overfitting can be avoided, overfitting happens relatively as we have a small dataset, and we try to learn from it.\n",
    "\n",
    "b) By using cross validation: If we have a small database and we are forced to come with a model based on that. In such situation, we can use a technique known as cross validation. In this method the dataset splits into two section, testing and training datasets, the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
